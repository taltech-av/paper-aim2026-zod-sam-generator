{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95ce58b",
   "metadata": {},
   "source": [
    "# ZOD (Zenseact Open Dataset) - Complete Dataset Overview\n",
    "\n",
    "This notebook provides a complete overview and analysis of the **Zenseact Open Dataset (ZOD)** - one of the world's largest and most comprehensive autonomous driving datasets. We'll explore the massive dataset we've downloaded, analyze its structure, and demonstrate various data types including camera images, LiDAR point clouds, and rich annotations.\n",
    "\n",
    "### üìä Dataset Highlights:\n",
    "- **Scale**: 100,000 frames (1.4TB extracted)\n",
    "- **Sensors**: Multi-camera setup + LiDAR Velodyne\n",
    "- **Annotations**: Rich 3D bounding boxes and object detection\n",
    "- **Location**: Swedish driving conditions and scenarios\n",
    "- **Quality**: High-resolution sensor data with precise calibration\n",
    "\n",
    "### üéØ Analysis Goals:\n",
    "1. **File Structure Analysis**: Understand downloaded and extracted data organization\n",
    "2. **Data Type Exploration**: Camera images, LiDAR point clouds, annotations\n",
    "3. **Sample Visualizations**: Display various sensor modalities\n",
    "4. **Dataset Statistics**: Comprehensive size and content analysis\n",
    "5. **Usage Examples**: Practical code for working with ZOD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af8626",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee62ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üöó Ready for ZOD dataset analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üöó Ready for ZOD dataset analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfcdc6",
   "metadata": {},
   "source": [
    "## 2. Dataset Paths and Configuration\n",
    "\n",
    "Let's set up the paths to our ZOD dataset and configure basic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a11fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è  ZOD Data Path: /media/tom/ml/zod-data\n",
      "üìÅ Single Frames: /media/tom/ml/zod-data/single_frames\n",
      "üì• Downloads: /media/tom/ml/zod-data/downloads\n",
      "üî¨ Analysis Output: /media/tom/ml/projects/clft-zod/output/analysis\n",
      "\n",
      "üìä Path Status:\n",
      "‚úÖ ZOD Data: Found\n",
      "‚úÖ Single Frames: Found\n",
      "‚úÖ Downloads: Found\n",
      "‚úÖ Analysis Output: Found\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "ZOD_DATA_PATH = \"/media/tom/ml/zod-data\"\n",
    "SINGLE_FRAMES_PATH = os.path.join(ZOD_DATA_PATH, \"single_frames\")\n",
    "DOWNLOADS_PATH = os.path.join(ZOD_DATA_PATH, \"downloads\")\n",
    "\n",
    "# Project paths\n",
    "PROJECT_PATH = \"/media/tom/ml/projects/clft-zod\"\n",
    "OUTPUT_PATH = os.path.join(PROJECT_PATH, \"output\")\n",
    "ANALYSIS_PATH = os.path.join(OUTPUT_PATH, \"analysis\")\n",
    "\n",
    "print(f\"üóÇÔ∏è  ZOD Data Path: {ZOD_DATA_PATH}\")\n",
    "print(f\"üìÅ Single Frames: {SINGLE_FRAMES_PATH}\")\n",
    "print(f\"üì• Downloads: {DOWNLOADS_PATH}\")\n",
    "print(f\"üî¨ Analysis Output: {ANALYSIS_PATH}\")\n",
    "\n",
    "# Check if paths exist\n",
    "paths_status = {\n",
    "    \"ZOD Data\": os.path.exists(ZOD_DATA_PATH),\n",
    "    \"Single Frames\": os.path.exists(SINGLE_FRAMES_PATH),\n",
    "    \"Downloads\": os.path.exists(DOWNLOADS_PATH),\n",
    "    \"Analysis Output\": os.path.exists(ANALYSIS_PATH)\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Path Status:\")\n",
    "for path_name, exists in paths_status.items():\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"{status} {path_name}: {'Found' if exists else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0676ef",
   "metadata": {},
   "source": [
    "## 3. Dataset Size Analysis\n",
    "\n",
    "Let's analyze the size and structure of our downloaded ZOD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b4567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ZOD Dataset Analysis\n",
      "==================================================\n",
      "üì• Downloads folder: 1041.1 GB\n",
      "   ‚îî‚îÄ‚îÄ Directories: 1\n",
      "   ‚îî‚îÄ‚îÄ Files: 34\n",
      "üìÅ Single frames: 1333.1 GB\n",
      "   ‚îî‚îÄ‚îÄ Directories: 400,000\n",
      "   ‚îî‚îÄ‚îÄ Files: 1,231,936\n",
      "üî¢ Total dataset: 2374.6 GB\n",
      "üì¶ Compression ratio: 0.78 (1.3x expansion)\n",
      "üì• Downloads folder: 1041.1 GB\n",
      "   ‚îî‚îÄ‚îÄ Directories: 1\n",
      "   ‚îî‚îÄ‚îÄ Files: 34\n",
      "üìÅ Single frames: 1333.1 GB\n",
      "   ‚îî‚îÄ‚îÄ Directories: 400,000\n",
      "   ‚îî‚îÄ‚îÄ Files: 1,231,936\n",
      "üî¢ Total dataset: 2374.6 GB\n",
      "üì¶ Compression ratio: 0.78 (1.3x expansion)\n"
     ]
    }
   ],
   "source": [
    "def get_directory_size(path):\n",
    "    \"\"\"Calculate the total size of a directory in GB\"\"\"\n",
    "    total_size = 0\n",
    "    if os.path.exists(path):\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    total_size += os.path.getsize(filepath)\n",
    "                except (OSError, FileNotFoundError):\n",
    "                    pass\n",
    "    return total_size / (1024**3)  # Convert to GB\n",
    "\n",
    "def count_directories_and_files(path):\n",
    "    \"\"\"Count directories and files in a path\"\"\"\n",
    "    dirs = 0\n",
    "    files = 0\n",
    "    if os.path.exists(path):\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            dirs += len(dirnames)\n",
    "            files += len(filenames)\n",
    "    return dirs, files\n",
    "\n",
    "# Analyze dataset sizes\n",
    "if os.path.exists(ZOD_DATA_PATH):\n",
    "    print(\"üìä ZOD Dataset Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Downloads analysis\n",
    "    downloads_size = get_directory_size(DOWNLOADS_PATH)\n",
    "    downloads_dirs, downloads_files = count_directories_and_files(DOWNLOADS_PATH)\n",
    "    \n",
    "    # Single frames analysis  \n",
    "    frames_size = get_directory_size(SINGLE_FRAMES_PATH)\n",
    "    frames_dirs, frames_files = count_directories_and_files(SINGLE_FRAMES_PATH)\n",
    "    \n",
    "    # Total dataset size\n",
    "    total_size = get_directory_size(ZOD_DATA_PATH)\n",
    "    \n",
    "    print(f\"üì• Downloads folder: {downloads_size:.1f} GB\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Directories: {downloads_dirs:,}\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Files: {downloads_files:,}\")\n",
    "    \n",
    "    print(f\"üìÅ Single frames: {frames_size:.1f} GB\") \n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Directories: {frames_dirs:,}\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Files: {frames_files:,}\")\n",
    "    \n",
    "    print(f\"üî¢ Total dataset: {total_size:.1f} GB\")\n",
    "    \n",
    "    # Compression ratio\n",
    "    if downloads_size > 0 and frames_size > 0:\n",
    "        compression_ratio = downloads_size / frames_size\n",
    "        print(f\"üì¶ Compression ratio: {compression_ratio:.2f} ({frames_size/downloads_size:.1f}x expansion)\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå ZOD dataset path not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a9978",
   "metadata": {},
   "source": [
    "## 4. Frame Structure Exploration\n",
    "\n",
    "Let's explore the structure of individual frames in the ZOD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae41615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è  Found 100000 frame directories\n",
      "üìã Sample frame IDs: ['000000', '000001', '000002', '000003', '000004', '000005', '000006', '000007', '000008', '000009']\n",
      "\n",
      "üîç Analyzing frame structure: 000000\n",
      "==================================================\n",
      "üìÅ annotations/ (4 files)\n",
      "üìÑ calibration.json (1.1 KB)\n",
      "üìÅ camera_front_blur/ (1 files)\n",
      "üìÑ ego_motion.json (10.9 KB)\n",
      "üìÑ info.json (4.6 KB)\n",
      "üìÅ lidar_velodyne/ (3 files)\n",
      "üìÑ metadata.json (479 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Get list of frame directories\n",
    "if os.path.exists(SINGLE_FRAMES_PATH):\n",
    "    frame_dirs = [d for d in os.listdir(SINGLE_FRAMES_PATH) \n",
    "                  if os.path.isdir(os.path.join(SINGLE_FRAMES_PATH, d))]\n",
    "    frame_dirs.sort()\n",
    "    \n",
    "    print(f\"üóÇÔ∏è  Found {len(frame_dirs)} frame directories\")\n",
    "    print(f\"üìã Sample frame IDs: {frame_dirs[:10]}\")\n",
    "    \n",
    "    # Analyze structure of first frame\n",
    "    if frame_dirs:\n",
    "        sample_frame = frame_dirs[0]\n",
    "        sample_path = os.path.join(SINGLE_FRAMES_PATH, sample_frame)\n",
    "        \n",
    "        print(f\"\\nüîç Analyzing frame structure: {sample_frame}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # List contents\n",
    "        contents = os.listdir(sample_path)\n",
    "        contents.sort()\n",
    "        \n",
    "        for item in contents:\n",
    "            item_path = os.path.join(sample_path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                # Count files in subdirectory\n",
    "                sub_contents = os.listdir(item_path)\n",
    "                print(f\"üìÅ {item}/ ({len(sub_contents)} files)\")\n",
    "            else:\n",
    "                # Get file size\n",
    "                size = os.path.getsize(item_path)\n",
    "                if size > 1024*1024:  # > 1MB\n",
    "                    size_str = f\"{size/(1024*1024):.1f} MB\"\n",
    "                elif size > 1024:  # > 1KB\n",
    "                    size_str = f\"{size/1024:.1f} KB\"\n",
    "                else:\n",
    "                    size_str = f\"{size} bytes\"\n",
    "                print(f\"üìÑ {item} ({size_str})\")\n",
    "                \n",
    "else:\n",
    "    print(\"‚ùå Single frames path not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a69a6",
   "metadata": {},
   "source": [
    "## 5. Sample Data Loading and Visualization\n",
    "\n",
    "Let's load and visualize sample data from the ZOD dataset to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d72371dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading sample frame: 000000\n",
      "==================================================\n",
      "‚úÖ Loaded metadata.json\n",
      "‚úÖ Loaded info.json\n",
      "‚úÖ Loaded ego_motion.json\n",
      "‚ö†Ô∏è  object_detection.json not found\n",
      "‚úÖ Loaded calibration.json\n",
      "üì∑ Found 1 camera images\n",
      "üì° Found 0 LiDAR files\n",
      "üè∑Ô∏è  Found 4 annotation files\n"
     ]
    }
   ],
   "source": [
    "def load_sample_frame_data(frame_id):\n",
    "    \"\"\"Load sample data from a ZOD frame\"\"\"\n",
    "    frame_path = os.path.join(SINGLE_FRAMES_PATH, frame_id)\n",
    "    \n",
    "    if not os.path.exists(frame_path):\n",
    "        print(f\"‚ùå Frame {frame_id} not found!\")\n",
    "        return None\n",
    "        \n",
    "    data = {}\n",
    "    \n",
    "    # Load JSON files\n",
    "    json_files = ['metadata.json', 'info.json', 'ego_motion.json', \n",
    "                  'object_detection.json', 'calibration.json']\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        json_path = os.path.join(frame_path, json_file)\n",
    "        if os.path.exists(json_path):\n",
    "            try:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data[json_file.replace('.json', '')] = json.load(f)\n",
    "                print(f\"‚úÖ Loaded {json_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {json_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {json_file} not found\")\n",
    "    \n",
    "    # Check for camera images\n",
    "    camera_dir = os.path.join(frame_path, 'camera_front_blur')\n",
    "    if os.path.exists(camera_dir):\n",
    "        camera_files = [f for f in os.listdir(camera_dir) if f.endswith(('.jpg', '.png'))]\n",
    "        data['camera_files'] = camera_files\n",
    "        print(f\"üì∑ Found {len(camera_files)} camera images\")\n",
    "    \n",
    "    # Check for LiDAR data\n",
    "    lidar_dir = os.path.join(frame_path, 'lidar_velodyne')\n",
    "    if os.path.exists(lidar_dir):\n",
    "        lidar_files = [f for f in os.listdir(lidar_dir) if f.endswith('.bin')]\n",
    "        data['lidar_files'] = lidar_files\n",
    "        print(f\"üì° Found {len(lidar_files)} LiDAR files\")\n",
    "        \n",
    "    # Check for annotations\n",
    "    annotations_dir = os.path.join(frame_path, 'annotations')\n",
    "    if os.path.exists(annotations_dir):\n",
    "        annotation_files = [f for f in os.listdir(annotations_dir)]\n",
    "        data['annotation_files'] = annotation_files\n",
    "        print(f\"üè∑Ô∏è  Found {len(annotation_files)} annotation files\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load sample frame\n",
    "if 'frame_dirs' in locals() and frame_dirs:\n",
    "    sample_frame_id = frame_dirs[0]\n",
    "    print(f\"üîç Loading sample frame: {sample_frame_id}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    sample_data = load_sample_frame_data(sample_frame_id)\n",
    "else:\n",
    "    print(\"‚ùå No frame directories available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d1647",
   "metadata": {},
   "source": [
    "### 5.1 Metadata Analysis\n",
    "\n",
    "Let's examine the metadata structure from our sample frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f39fa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Metadata Structure Analysis\n",
      "==================================================\n",
      "üîπ road_type: city\n",
      "\n",
      "üìã All metadata fields (17 total):\n",
      "   ‚Ä¢ collection_car (str)\n",
      "   ‚Ä¢ country_code (str)\n",
      "   ‚Ä¢ frame_id (str)\n",
      "   ‚Ä¢ latitude (float)\n",
      "   ‚Ä¢ longitude (float)\n",
      "   ‚Ä¢ num_lane_instances (int)\n",
      "   ‚Ä¢ num_pedestrians (int)\n",
      "   ‚Ä¢ num_traffic_lights (int)\n",
      "   ‚Ä¢ num_traffic_signs (int)\n",
      "   ‚Ä¢ num_vehicles (int)\n",
      "   ‚Ä¢ num_vulnerable_vehicles (int)\n",
      "   ‚Ä¢ road_condition (str)\n",
      "   ‚Ä¢ road_type (str)\n",
      "   ‚Ä¢ scraped_weather (str)\n",
      "   ‚Ä¢ solar_angle_elevation (float)\n",
      "   ‚Ä¢ time (str)\n",
      "   ‚Ä¢ time_of_day (str)\n"
     ]
    }
   ],
   "source": [
    "# Analyze metadata structure\n",
    "if 'sample_data' in locals() and sample_data and 'metadata' in sample_data:\n",
    "    metadata = sample_data['metadata']\n",
    "    \n",
    "    print(\"üìä Metadata Structure Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display key metadata fields\n",
    "    key_fields = ['timestamp', 'weather', 'timeofday', 'road_type', 'location']\n",
    "    \n",
    "    for field in key_fields:\n",
    "        if field in metadata:\n",
    "            value = metadata[field]\n",
    "            print(f\"üîπ {field}: {value}\")\n",
    "    \n",
    "    # Show all available fields\n",
    "    print(f\"\\nüìã All metadata fields ({len(metadata)} total):\")\n",
    "    for key in sorted(metadata.keys()):\n",
    "        value_type = type(metadata[key]).__name__\n",
    "        print(f\"   ‚Ä¢ {key} ({value_type})\")\n",
    "        \n",
    "    # Display weather and time information\n",
    "    if 'weather' in metadata and 'timeofday' in metadata:\n",
    "        print(f\"\\nüå§Ô∏è  Scene conditions:\")\n",
    "        print(f\"   Weather: {metadata['weather']}\")\n",
    "        print(f\"   Time of day: {metadata['timeofday']}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No metadata available in sample data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
